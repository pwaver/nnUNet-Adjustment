{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "# Example paths (adjust as needed)\n",
    "# angiographyDataFile = \"/path/to/your/angiography.h5\"\n",
    "# nnUNetRawFolder = \"/path/to/nnUNet/raw/folder\"\n",
    "angiographyDataFile = \"/home/ubuntu/Angiostore/WebknossosAngiogramsRevisedUInt8List.h5\"\n",
    "annotationDataFile = \"/home/ubuntu/Angiostore/WebknossosAnnotationsRevisedUnitized-5.h5\"\n",
    "annotationIndicizedDataFile = \"/home/ubuntu/Angiostore/WebknossosAnnotationsRevisedIndicized-3.h5\"\n",
    "nnUNetRawFolder = \"/home/ubuntu/Angiostore/nnUnet_raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_keys(angiographyDataFile, annotationDataFile):\n",
    "    \"\"\"\n",
    "    Get the intersection of keys between the two HDF5 files\n",
    "    \"\"\"\n",
    "    with h5py.File(angiographyDataFile, 'r') as f_angio, \\\n",
    "         h5py.File(annotationDataFile, 'r') as f_anno:\n",
    "        \n",
    "        angio_keys = set(f_angio.keys())\n",
    "        anno_keys = set(f_anno.keys())\n",
    "        common_keys = sorted(list(angio_keys.intersection(anno_keys)))\n",
    "        \n",
    "        print(f\"Angiography keys: {len(angio_keys)}\")\n",
    "        print(f\"Annotation keys: {len(anno_keys)}\")\n",
    "        print(f\"Common keys: {len(common_keys)}\")\n",
    "        \n",
    "        return common_keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angiography keys: 160\n",
      "Annotation keys: 129\n",
      "Common keys: 129\n",
      "Common keys: ['01_Case_CSF8U1R1_14', '01_Case_CSF8U1RQ_13', '03_Case_CSF8UKA1_2', '03_Case_CSF8UKA5_4', '03_Case_CSF8UKA9_1', '03_Case_CSF8UKAH_5', '06_Case_CSF8W343_9', '10_Case_CSF8WNXU_5', '10_Case_CSF8WNY6_1', '12_Case_CSF8XAD2_23', '12_Case_CSF8XADW_10', '13_Case_CSVS1XAP_1', '13_Case_CSVS1XAU_6', '13_Case_CSVS1XB4_2', '14_Case_CSVS23F6_14', '14_Case_CSVS23FO_5', '14_Case_CSVS23FS_4', 'Angios_005_rev', 'Angios_006_rev', 'Angios_007_rev', 'Angios_013_rev', 'Angios_015_rev', 'Angios_016_rev', 'Angios_021_rev', 'Angios_022_rev', 'Angios_030_rev', 'Angios_031_rev', 'Angios_032_rev', 'Angios_048_rev', 'Angios_061_rev', 'Angios_063_rev', 'Angios_065_rev', 'Angios_067_rev', 'Angios_072_rev', 'Angios_075_rev', 'Angios_079_rev', 'Angios_081_rev', 'Angios_082_rev', 'Angios_104_rev', 'Angios_114_rev', 'Angios_120_rev', 'Angios_128_rev', 'Angios_129_rev', 'Angios_133_rev', 'Angios_148_rev', 'Angios_157_rev', 'Angios_161_rev', 'Angios_164_rev', 'Angios_168_rev', 'Angios_170_rev', 'Angios_181_rev', 'Angios_190_rev', 'Angios_197_rev', 'Napari_0_rev', 'Napari_101_rev', 'Napari_10_rev', 'Napari_12_rev', 'Napari_13_rev', 'Napari_14_rev', 'Napari_15_rev', 'Napari_16_rev', 'Napari_17_rev', 'Napari_19_rev', 'Napari_1_rev', 'Napari_20_rev', 'Napari_22_rev', 'Napari_25_rev', 'Napari_26_rev', 'Napari_27_rev', 'Napari_28_rev', 'Napari_30_rev', 'Napari_31_rev', 'Napari_33_rev', 'Napari_35_rev', 'Napari_36_rev', 'Napari_37_rev', 'Napari_38_rev', 'Napari_39_rev', 'Napari_3_rev', 'Napari_40_rev', 'Napari_41_rev', 'Napari_42_rev', 'Napari_44_rev', 'Napari_45_rev', 'Napari_46_rev', 'Napari_47_rev', 'Napari_49_rev', 'Napari_52_rev', 'Napari_53_rev', 'Napari_54_rev', 'Napari_55_rev', 'Napari_56_rev', 'Napari_57_rev', 'Napari_58_rev', 'Napari_5_rev', 'Napari_60_rev', 'Napari_61_rev', 'Napari_62_rev', 'Napari_66_rev', 'Napari_68_rev', 'Napari_69_rev', 'Napari_71_rev', 'Napari_75_rev', 'Napari_76_rev', 'Napari_77_rev', 'Napari_79_rev', 'Napari_80_rev', 'Napari_81_rev', 'Napari_82_rev', 'Napari_83_rev', 'Napari_84_rev', 'Napari_85_rev', 'Napari_87_rev', 'Napari_88_rev', 'Napari_89_rev', 'Napari_8_rev', 'Napari_90_rev', 'Napari_91_rev', 'Napari_92_rev', 'Napari_93_rev', 'Napari_94_rev', 'Napari_95_rev', 'Napari_96_rev', 'Napari_97_rev', 'Napari_98_rev', 'Napari_99_rev', 'Napari_9_rev', 'Narapi_24_rev', 'Narapi_34_rev']\n"
     ]
    }
   ],
   "source": [
    "# Get common keys first\n",
    "common_keys = get_common_keys(angiographyDataFile, annotationDataFile)\n",
    "\n",
    "# If you want to see the keys before proceeding\n",
    "print(\"Common keys:\", common_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def export_angiography_to_nnunet(angiographyDataFile, nnUNetRawFolder, common_keys):\n",
    "    \"\"\"\n",
    "    Modified to only process common keys\n",
    "    \"\"\"\n",
    "    images_dir = os.path.join(nnUNetRawFolder, 'imagesTr')\n",
    "    Path(images_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    frameKeys=[]\n",
    "    \n",
    "    with h5py.File(angiographyDataFile, 'r') as f:\n",
    "        blockCounter = 0\n",
    "        \n",
    "        # Only iterate through common keys\n",
    "        for dataset_name in common_keys:\n",
    "            print(f\"Processing angiogram dataset: {dataset_name}\")\n",
    "            angio_data = f[dataset_name][:]\n",
    "            \n",
    "            n_frames = angio_data.shape[0]\n",
    "            \n",
    "            for center_idx in range(2, n_frames - 2):\n",
    "                frameKeys.append([dataset_name, center_idx])\n",
    "                frame_indices = range(center_idx - 2, center_idx + 3)\n",
    "                frames = angio_data[frame_indices]\n",
    "                \n",
    "                for frame_num, frame in enumerate(frames):\n",
    "                    if frame.dtype != np.uint8:\n",
    "                        if frame.max() > 1:\n",
    "                            frame = (frame / frame.max() * 255).astype(np.uint8)\n",
    "                        else:\n",
    "                            frame = (frame * 255).astype(np.uint8)\n",
    "                    \n",
    "                    filename = f'Angios_{blockCounter:04d}_{frame_num:04d}.png'\n",
    "                    filepath = os.path.join(images_dir, filename)\n",
    "                    cv2.imwrite(filepath, frame)\n",
    "                \n",
    "                blockCounter += 1\n",
    "        \n",
    "        print(f\"Exported {blockCounter} sets of 5 frames each\")\n",
    "        print(f\"Total number of PNG files created: {blockCounter * 5}\")\n",
    "        return frameKeys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing angiogram dataset: 01_Case_CSF8U1R1_14\n",
      "Processing angiogram dataset: 01_Case_CSF8U1RQ_13\n",
      "Processing angiogram dataset: 03_Case_CSF8UKA1_2\n",
      "Processing angiogram dataset: 03_Case_CSF8UKA5_4\n",
      "Processing angiogram dataset: 03_Case_CSF8UKA9_1\n",
      "Processing angiogram dataset: 03_Case_CSF8UKAH_5\n",
      "Processing angiogram dataset: 06_Case_CSF8W343_9\n",
      "Processing angiogram dataset: 10_Case_CSF8WNXU_5\n",
      "Processing angiogram dataset: 10_Case_CSF8WNY6_1\n",
      "Processing angiogram dataset: 12_Case_CSF8XAD2_23\n",
      "Processing angiogram dataset: 12_Case_CSF8XADW_10\n",
      "Processing angiogram dataset: 13_Case_CSVS1XAP_1\n",
      "Processing angiogram dataset: 13_Case_CSVS1XAU_6\n",
      "Processing angiogram dataset: 13_Case_CSVS1XB4_2\n",
      "Processing angiogram dataset: 14_Case_CSVS23F6_14\n",
      "Processing angiogram dataset: 14_Case_CSVS23FO_5\n",
      "Processing angiogram dataset: 14_Case_CSVS23FS_4\n",
      "Processing angiogram dataset: Angios_005_rev\n",
      "Processing angiogram dataset: Angios_006_rev\n",
      "Processing angiogram dataset: Angios_007_rev\n",
      "Processing angiogram dataset: Angios_013_rev\n",
      "Processing angiogram dataset: Angios_015_rev\n",
      "Processing angiogram dataset: Angios_016_rev\n",
      "Processing angiogram dataset: Angios_021_rev\n",
      "Processing angiogram dataset: Angios_022_rev\n",
      "Processing angiogram dataset: Angios_030_rev\n",
      "Processing angiogram dataset: Angios_031_rev\n",
      "Processing angiogram dataset: Angios_032_rev\n",
      "Processing angiogram dataset: Angios_048_rev\n",
      "Processing angiogram dataset: Angios_061_rev\n",
      "Processing angiogram dataset: Angios_063_rev\n",
      "Processing angiogram dataset: Angios_065_rev\n",
      "Processing angiogram dataset: Angios_067_rev\n",
      "Processing angiogram dataset: Angios_072_rev\n",
      "Processing angiogram dataset: Angios_075_rev\n",
      "Processing angiogram dataset: Angios_079_rev\n",
      "Processing angiogram dataset: Angios_081_rev\n",
      "Processing angiogram dataset: Angios_082_rev\n",
      "Processing angiogram dataset: Angios_104_rev\n",
      "Processing angiogram dataset: Angios_114_rev\n",
      "Processing angiogram dataset: Angios_120_rev\n",
      "Processing angiogram dataset: Angios_128_rev\n",
      "Processing angiogram dataset: Angios_129_rev\n",
      "Processing angiogram dataset: Angios_133_rev\n",
      "Processing angiogram dataset: Angios_148_rev\n",
      "Processing angiogram dataset: Angios_157_rev\n",
      "Processing angiogram dataset: Angios_161_rev\n",
      "Processing angiogram dataset: Angios_164_rev\n",
      "Processing angiogram dataset: Angios_168_rev\n",
      "Processing angiogram dataset: Angios_170_rev\n",
      "Processing angiogram dataset: Angios_181_rev\n",
      "Processing angiogram dataset: Angios_190_rev\n",
      "Processing angiogram dataset: Angios_197_rev\n",
      "Processing angiogram dataset: Napari_0_rev\n",
      "Processing angiogram dataset: Napari_101_rev\n",
      "Processing angiogram dataset: Napari_10_rev\n",
      "Processing angiogram dataset: Napari_12_rev\n",
      "Processing angiogram dataset: Napari_13_rev\n",
      "Processing angiogram dataset: Napari_14_rev\n",
      "Processing angiogram dataset: Napari_15_rev\n",
      "Processing angiogram dataset: Napari_16_rev\n",
      "Processing angiogram dataset: Napari_17_rev\n",
      "Processing angiogram dataset: Napari_19_rev\n",
      "Processing angiogram dataset: Napari_1_rev\n",
      "Processing angiogram dataset: Napari_20_rev\n",
      "Processing angiogram dataset: Napari_22_rev\n",
      "Processing angiogram dataset: Napari_25_rev\n",
      "Processing angiogram dataset: Napari_26_rev\n",
      "Processing angiogram dataset: Napari_27_rev\n",
      "Processing angiogram dataset: Napari_28_rev\n",
      "Processing angiogram dataset: Napari_30_rev\n",
      "Processing angiogram dataset: Napari_31_rev\n",
      "Processing angiogram dataset: Napari_33_rev\n",
      "Processing angiogram dataset: Napari_35_rev\n",
      "Processing angiogram dataset: Napari_36_rev\n",
      "Processing angiogram dataset: Napari_37_rev\n",
      "Processing angiogram dataset: Napari_38_rev\n",
      "Processing angiogram dataset: Napari_39_rev\n",
      "Processing angiogram dataset: Napari_3_rev\n",
      "Processing angiogram dataset: Napari_40_rev\n",
      "Processing angiogram dataset: Napari_41_rev\n",
      "Processing angiogram dataset: Napari_42_rev\n",
      "Processing angiogram dataset: Napari_44_rev\n",
      "Processing angiogram dataset: Napari_45_rev\n",
      "Processing angiogram dataset: Napari_46_rev\n",
      "Processing angiogram dataset: Napari_47_rev\n",
      "Processing angiogram dataset: Napari_49_rev\n",
      "Processing angiogram dataset: Napari_52_rev\n",
      "Processing angiogram dataset: Napari_53_rev\n",
      "Processing angiogram dataset: Napari_54_rev\n",
      "Processing angiogram dataset: Napari_55_rev\n",
      "Processing angiogram dataset: Napari_56_rev\n",
      "Processing angiogram dataset: Napari_57_rev\n",
      "Processing angiogram dataset: Napari_58_rev\n",
      "Processing angiogram dataset: Napari_5_rev\n",
      "Processing angiogram dataset: Napari_60_rev\n",
      "Processing angiogram dataset: Napari_61_rev\n",
      "Processing angiogram dataset: Napari_62_rev\n",
      "Processing angiogram dataset: Napari_66_rev\n",
      "Processing angiogram dataset: Napari_68_rev\n",
      "Processing angiogram dataset: Napari_69_rev\n",
      "Processing angiogram dataset: Napari_71_rev\n",
      "Processing angiogram dataset: Napari_75_rev\n",
      "Processing angiogram dataset: Napari_76_rev\n",
      "Processing angiogram dataset: Napari_77_rev\n",
      "Processing angiogram dataset: Napari_79_rev\n",
      "Processing angiogram dataset: Napari_80_rev\n",
      "Processing angiogram dataset: Napari_81_rev\n",
      "Processing angiogram dataset: Napari_82_rev\n",
      "Processing angiogram dataset: Napari_83_rev\n",
      "Processing angiogram dataset: Napari_84_rev\n",
      "Processing angiogram dataset: Napari_85_rev\n",
      "Processing angiogram dataset: Napari_87_rev\n",
      "Processing angiogram dataset: Napari_88_rev\n",
      "Processing angiogram dataset: Napari_89_rev\n",
      "Processing angiogram dataset: Napari_8_rev\n",
      "Processing angiogram dataset: Napari_90_rev\n",
      "Processing angiogram dataset: Napari_91_rev\n",
      "Processing angiogram dataset: Napari_92_rev\n",
      "Processing angiogram dataset: Napari_93_rev\n",
      "Processing angiogram dataset: Napari_94_rev\n",
      "Processing angiogram dataset: Napari_95_rev\n",
      "Processing angiogram dataset: Napari_96_rev\n",
      "Processing angiogram dataset: Napari_97_rev\n",
      "Processing angiogram dataset: Napari_98_rev\n",
      "Processing angiogram dataset: Napari_99_rev\n",
      "Processing angiogram dataset: Napari_9_rev\n",
      "Processing angiogram dataset: Narapi_24_rev\n",
      "Processing angiogram dataset: Narapi_34_rev\n",
      "Exported 8371 sets of 5 frames each\n",
      "Total number of PNG files created: 41855\n"
     ]
    }
   ],
   "source": [
    "frameKeys = export_angiography_to_nnunet(angiographyDataFile, nnUNetRawFolder, common_keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def indicize_annotations(annotationDataFile, annotationIndicizedDataFile):\n",
    "    \"\"\"\n",
    "    Transform 5-channel unitized annotations to single-channel indicized format.\n",
    "    \n",
    "    Rules:\n",
    "    (0,0,0,*,*) -> 0  # background\n",
    "    (0,1,0,*,*) -> 1  # catheter\n",
    "    (0,0,1,0,*) -> 2  # vessel\n",
    "    (0,0,*,1,*) -> 0  # stenosis (maps to background)\n",
    "    \"\"\"\n",
    "    \n",
    "    def dataset_transform(data):\n",
    "        catheter = data[1]\n",
    "        vessel =  2 * (data[2] - data[2]*data[3]) \n",
    "        result = catheter + vessel - data[1]*data[2] \n",
    "        \n",
    "        return result\n",
    "    \n",
    "    # Open both files\n",
    "    with h5py.File(annotationDataFile, 'r') as f_in, \\\n",
    "         h5py.File(annotationIndicizedDataFile, 'w') as f_out:\n",
    "        \n",
    "        # Process each dataset\n",
    "        for dataset_name in f_in.keys():\n",
    "            print(f\"Processing dataset: {dataset_name}\")\n",
    "            \n",
    "            # Read input data\n",
    "            data = f_in[dataset_name][:]\n",
    "            print(f\"Dataset shape: {data.shape}\")\n",
    "            transformed = dataset_transform(data)\n",
    "            print(f\"Transformed shape: {transformed.shape}\")\n",
    "            \n",
    "            # Create output dataset\n",
    "            output_shape = transformed.shape\n",
    "            dset_out = f_out.create_dataset(\n",
    "                dataset_name,\n",
    "                output_shape,\n",
    "                dtype=np.uint8\n",
    "            )\n",
    "            \n",
    "            # Write transformed data\n",
    "            dset_out[:] = transformed\n",
    "            \n",
    "            # Verify unique values\n",
    "            unique_values = np.unique(dset_out[:])\n",
    "            print(f\"  Dataset {dataset_name} unique values: {unique_values}\")\n",
    "            \n",
    "        print(\"Transformation complete!\")\n",
    "\n",
    "# Example usage:\n",
    "# transform_annotations(annotationDataFile, annotationIndicizedDataFile)\n",
    "\n",
    "# For debugging, let's also print the shape of the first dataset\n",
    "with h5py.File(annotationDataFile, 'r') as f:\n",
    "    first_dataset_name = list(f.keys())[0]\n",
    "    first_dataset = f[first_dataset_name][:]\n",
    "    print(f\"First dataset shape: {first_dataset.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example paths (adjust as needed)\n",
    "# annotationDataFile = \"/path/to/5channel/annotations.h5\"\n",
    "# annotationIndicizedDataFile = \"/path/to/output/indicized_annotations.h5\"\n",
    "\n",
    "indicize_annotations(annotationDataFile, annotationIndicizedDataFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hdf5_keys(hdf5_file: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Get list of dataset keys in an HDF5 file.\n",
    "\n",
    "    Args:\n",
    "        hdf5_file: Path to the HDF5 file\n",
    "\n",
    "    Returns:\n",
    "        list[str]: List of dataset keys in the file\n",
    "    \"\"\"\n",
    "    with h5py.File(hdf5_file, 'r') as f:\n",
    "        keys = list(f.keys())\n",
    "        print(f\"Keys in {hdf5_file}:\")\n",
    "        for key in keys:\n",
    "            print(f\"  {key}\")\n",
    "        return keys\n",
    "\n",
    "# Get keys from annotationIndicizedDataFile\n",
    "keys = get_hdf5_keys(annotationIndicizedDataFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_data(hdf5_file: str, key: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Get data from a specific dataset in an HDF5 file.\n",
    "\n",
    "    Args:\n",
    "        hdf5_file: Path to the HDF5 file\n",
    "        key: Key of the dataset to retrieve\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Data from the specified dataset\n",
    "    \"\"\"\n",
    "    with h5py.File(hdf5_file, 'r') as f:\n",
    "        data = f[key][:]\n",
    "        print(f\"Shape of dataset {key}: {data.shape}\")\n",
    "        return data\n",
    "\n",
    "# Get data for \"Napari_9_rev\" dataset\n",
    "key = random.choice(keys)\n",
    "example_data = get_dataset_data(annotationIndicizedDataFile, key)\n",
    "print(key, example_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display as an image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(example_data[30], cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.title('example_data[30]')\n",
    "plt.axis('on')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def export_annotations_to_nnunet(annotationDataFile, nnUNetRawFolder, frameKeys):\n",
    "    \"\"\"\n",
    "    Modified to only process common keys and verify count matches angiography\n",
    "    \"\"\"\n",
    "    labels_dir = os.path.join(nnUNetRawFolder, 'labelsTr')\n",
    "    Path(labels_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with h5py.File(annotationDataFile, 'r') as f:\n",
    "        blockCounter = 0\n",
    "        \n",
    "        # Only iterate through common keys\n",
    "        for dataset_name, center_idx in frameKeys:\n",
    "            print(f\"Processing annotation dataset: {dataset_name}\")\n",
    "            anno_data = f[dataset_name][center_idx]\n",
    "            \n",
    "            filename = f'Angios_{blockCounter:04d}.png'\n",
    "            filepath = os.path.join(labels_dir, filename)\n",
    "            cv2.imwrite(filepath, anno_data)\n",
    "                \n",
    "            blockCounter += 1\n",
    "        \n",
    "        print(f\"Exported {blockCounter} label files\")\n",
    "        \n",
    "        # Verify we have the same number of cases as angiography\n",
    "        assert blockCounter == len(frameKeys), \\\n",
    "            f\"Mismatch in number of cases: Angiography had {len(frameKeys)}, Annotations had {blockCounter}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print first 50 frame keys to inspect the data\n",
    "print(\"First 50 frame keys:\")\n",
    "for i, (dataset_name, center_idx) in enumerate(frameKeys[:50]):\n",
    "    print(f\"{i}: {dataset_name}, center_idx={center_idx}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_annotations_to_nnunet(annotationIndicizedDataFile, nnUNetRawFolder, frameKeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(frameKeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... existing code ...\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Get current timestamp in a human-readable format\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "datasetJson = {\n",
    "    \"_comment\": f\"Dataset contains 5-channel angiography data at 7.5Hz (every other frame) with 5-frame neighborhoods. Labels include background (0), C (1), and V (2). Data sourced from WebknossosAngiogramsRevisedUInt8List.h5 and WebknossosAnnotationsRevisedIndicized-3.h5. Generated on {timestamp}.\",\n",
    "    \"channel_names\": {\n",
    "        \"0\": \"0\",\n",
    "        \"1\": \"1\",\n",
    "        \"2\": \"2\",\n",
    "        \"3\": \"3\",\n",
    "        \"4\": \"4\"\n",
    "    },\n",
    "    \"labels\": {\n",
    "        \"background\": 0,\n",
    "        \"catheter\": 1,\n",
    "        \"vessel\": 2\n",
    "    },\n",
    "    \"numTraining\": len(frameKeys),\n",
    "    \"file_ending\": \".png\"\n",
    "}\n",
    "\n",
    "# Write the dataset.json file\n",
    "import json\n",
    "dataset_json_path = os.path.join(nnUNetRawFolder, 'dataset.json')\n",
    "with open(dataset_json_path, 'w') as f:\n",
    "    json.dump(datasetJson, f, indent=4)\n",
    "\n",
    "print(f\"Created dataset.json at {dataset_json_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "angioshear.venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
