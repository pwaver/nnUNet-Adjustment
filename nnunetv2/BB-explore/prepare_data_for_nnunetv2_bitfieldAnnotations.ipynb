{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "# Example paths (adjust as needed)\n",
    "# angiographyDataFile = \"/path/to/your/angiography.h5\"\n",
    "# nnUNetRawFolder = \"/path/to/nnUNet/raw/folder\"\n",
    "angiographyDataFile = \"/home/ubuntu/Angiostore/WebknossosAngiogramsRevisedUInt8List.h5\"\n",
    "annotationBitfieldDataFile = \"/home/ubuntu/Angiostore/WebknossosAnnotationsRevisedUnitized-5-Bitfield.h5\"\n",
    "annotationDataFile = \"/home/ubuntu/Angiostore/WebknossosAnnotationsRevisedUnitized-5.h5\"\n",
    "\n",
    "annotationIndicizedDataFile = \"/home/ubuntu/Angiostore/WebknossosAnnotationsRevisedIndicized-3.h5\"\n",
    "nnUNetRawFolder = \"/home/ubuntu/Angiostore/nnUnet_raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_keys(angiographyDataFile, annotationDataFile):\n",
    "    \"\"\"\n",
    "    Get the intersection of keys between the two HDF5 files\n",
    "    \"\"\"\n",
    "    with h5py.File(angiographyDataFile, 'r') as f_angio, \\\n",
    "         h5py.File(annotationDataFile, 'r') as f_anno:\n",
    "        \n",
    "        angio_keys = set(f_angio.keys())\n",
    "        anno_keys = set(f_anno.keys())\n",
    "        common_keys = sorted(list(angio_keys.intersection(anno_keys)))\n",
    "        \n",
    "        print(f\"Angiography keys: {len(angio_keys)}\")\n",
    "        print(f\"Annotation keys: {len(anno_keys)}\")\n",
    "        print(f\"Common keys: {len(common_keys)}\")\n",
    "        \n",
    "        return common_keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get common keys first\n",
    "common_keys = get_common_keys(angiographyDataFile, annotationBitfieldDataFile)\n",
    "\n",
    "# If you want to see the keys before proceeding\n",
    "print(\"Common keys:\", common_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_allowed_frame_keys(angiographyDataFile: str, annotationBitfieldDataFile: str, common_keys: list[str]) -> list[tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Get allowed frame keys by finding the minimum number of frames between angiography and annotation data\n",
    "    for each common key, and generating valid center indices.\n",
    "\n",
    "    Args:\n",
    "        angiographyDataFile: Path to the angiography HDF5 file\n",
    "        annotationBitfieldDataFile: Path to the annotation bitfield HDF5 file\n",
    "        common_keys: List of keys common to both HDF5 files\n",
    "\n",
    "    Returns:\n",
    "        List of tuples containing (dataset_name, center_idx) for valid frames\n",
    "    \"\"\"\n",
    "    frameKeys = []\n",
    "    \n",
    "    with h5py.File(angiographyDataFile, 'r') as f_angio, \\\n",
    "         h5py.File(annotationBitfieldDataFile, 'r') as f_anno:\n",
    "        \n",
    "        for dataset_name in common_keys:\n",
    "            # Get number of frames from both files\n",
    "            angio_frames = f_angio[dataset_name].shape[0]\n",
    "            anno_frames = f_anno[dataset_name].shape[0]\n",
    "            \n",
    "            # Find minimum number of frames\n",
    "            min_frames = min(angio_frames, anno_frames)\n",
    "            \n",
    "            # Generate valid center indices (2 to min_frames-2)\n",
    "            for center_idx in range(2, min_frames - 2):\n",
    "                frameKeys.append((dataset_name, center_idx))\n",
    "    \n",
    "    return frameKeys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the allowed frame keys\n",
    "frameKeys = get_allowed_frame_keys(angiographyDataFile, annotationBitfieldDataFile,common_keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(frameKeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def export_angiography_to_nnunet(angiographyDataFile, nnUNetRawFolder, frameKeys):\n",
    "    \"\"\"\n",
    "    Modified to only process common keys\n",
    "    \"\"\"\n",
    "    images_dir = os.path.join(nnUNetRawFolder, 'imagesTr')\n",
    "    Path(images_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with h5py.File(angiographyDataFile, 'r') as f:\n",
    "        blockCounter = 0\n",
    "        \n",
    "        # Only iterate through common keys\n",
    "        for dataset_name, center_idx in frameKeys:\n",
    "            print(f\"Processing angiogram dataset: {dataset_name} center_idx: {center_idx}\")\n",
    "            angio_data = f[dataset_name][:]\n",
    "            frame_indices = range(center_idx - 2, center_idx + 3)\n",
    "            frames = angio_data[frame_indices]\n",
    "                \n",
    "            for frame_num, frame in enumerate(frames):\n",
    "                if frame.dtype != np.uint8:\n",
    "                    if frame.max() > 1:\n",
    "                        frame = (frame / frame.max() * 255).astype(np.uint8)\n",
    "                    else:\n",
    "                        frame = (frame * 255).astype(np.uint8)\n",
    "                    \n",
    "                filename = f'Angios_{blockCounter:05d}_{frame_num:04d}.png'\n",
    "                filepath = os.path.join(images_dir, filename)\n",
    "                cv2.imwrite(filepath, frame)\n",
    "                \n",
    "            blockCounter += 1\n",
    "        \n",
    "    print(f\"Exported {blockCounter} sets of 5 frames each\")\n",
    "    print(f\"Total number of PNG files created: {blockCounter * 5}\")\n",
    "    return blockCounter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blockCounter = export_angiography_to_nnunet(angiographyDataFile, nnUNetRawFolder, frameKeys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... existing code ...\n",
    "\n",
    "def bitfield_to_channels(bitfield_array: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Transform a 3D array of uint8 bitfields into a 4D array of separate class channels.\n",
    "    \n",
    "    Args:\n",
    "        bitfield_array: Input array of shape (frames, height, width) containing uint8 bitfields\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Output array of shape (8, frames, height, width) where each channel\n",
    "                   represents the presence of a specific class (bit position)\n",
    "                   \n",
    "    Example:\n",
    "        >>> input_array = np.array([[[1, 2], [3, 4]]], dtype=np.uint8)\n",
    "        >>> output = bitfield_to_channels(input_array)\n",
    "        >>> # output[0] will be the mask for bit 0\n",
    "        >>> # output[1] will be the mask for bit 1\n",
    "        >>> # etc.\n",
    "    \"\"\"\n",
    "    # Get the shape of the input array\n",
    "    frames, height, width = bitfield_array.shape\n",
    "    \n",
    "    # Initialize output array with shape (8, frames, height, width)\n",
    "    output = np.zeros((8, frames, height, width), dtype=np.uint8)\n",
    "    \n",
    "    # For each bit position (0-7)\n",
    "    for bit in range(8):\n",
    "        # Create a mask for this bit position\n",
    "        mask = 1 << bit\n",
    "        # Check if the bit is set in each position\n",
    "        output[bit] = (bitfield_array & mask).astype(bool).astype(np.uint8)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Example usage:\n",
    "# channels = bitfield_to_channels(example_data)\n",
    "# print(f\"Input shape: {example_data.shape}\")\n",
    "# print(f\"Output shape: {channels.shape}\")\n",
    "# print(f\"Number of non-zero pixels per channel:\")\n",
    "# for i in range(8):\n",
    "#     print(f\"Channel {i}: {np.sum(channels[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expandBitfieldAnnotationFile(annotationBitfieldDataFile, annotationDataFile):\n",
    "    # open both files\n",
    "    with h5py.File(annotationBitfieldDataFile, 'r') as f_bitfield, \\\n",
    "         h5py.File(annotationDataFile, 'w') as f_anno:\n",
    "        \n",
    "        # get the keys\n",
    "        bitfield_keys = list(f_bitfield.keys())\n",
    "        # Process each dataset\n",
    "        for dataset_name in bitfield_keys:\n",
    "            print(f\"Processing dataset: {dataset_name}\")\n",
    "            \n",
    "            # Read input data\n",
    "            data = f_bitfield[dataset_name][:]\n",
    "            print(f\"Input shape: {data.shape}\")\n",
    "            \n",
    "            # Transform to channels\n",
    "            channels = bitfield_to_channels(data)[:4][::-1]  # Keep only first 4 channels and reverse their order to give background, catheter, vessel, stenosis, stent.\n",
    "            # Add background channel (1 where all channels are 0)\n",
    "            background = np.all(channels == 0, axis=0).astype(np.uint8)\n",
    "            channels = np.concatenate([background[np.newaxis, ...], channels], axis=0)\n",
    "            print(f\"Channels shape: {channels.shape}\")\n",
    "            \n",
    "            # Create output dataset\n",
    "            output_shape = channels.shape\n",
    "            dset_out = f_anno.create_dataset(\n",
    "                dataset_name,\n",
    "                output_shape,\n",
    "                dtype=np.uint8\n",
    "            )\n",
    "            \n",
    "            # Write transformed data\n",
    "            dset_out[:] = channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "\n",
    "\n",
    "expandBitfieldAnnotationFile(annotationBitfieldDataFile, annotationDataFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indicize_annotation(data):\n",
    "        catheter = data[1]\n",
    "        vessel =  2 * (data[2] - data[2]*data[3]) \n",
    "        result = catheter + vessel - data[1]*data[2] \n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def indicize_annotations(annotationDataFile, annotationIndicizedDataFile):\n",
    "    \"\"\"\n",
    "    Transform 5-channel unitized annotations to single-channel indicized format.\n",
    "    \n",
    "    Rules:\n",
    "    (0,0,0,*,*) -> 0  # background\n",
    "    (0,1,0,*,*) -> 1  # catheter\n",
    "    (0,0,1,0,*) -> 2  # vessel\n",
    "    (0,0,*,1,*) -> 0  # stenosis (maps to background)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Open both files\n",
    "    with h5py.File(annotationDataFile, 'r') as f_in, \\\n",
    "         h5py.File(annotationIndicizedDataFile, 'w') as f_out:\n",
    "        \n",
    "        # Process each dataset\n",
    "        for dataset_name in f_in.keys():\n",
    "            print(f\"Processing dataset: {dataset_name}\")\n",
    "            \n",
    "            # Read input data\n",
    "            data = f_in[dataset_name][:]\n",
    "            print(f\"Dataset shape: {data.shape}\")\n",
    "            # channels = bitfield_to_channels(data)\n",
    "            # print(f\"channels shape: {channels.shape}\")\n",
    "            indicized = indicize_annotation(data)\n",
    "            print(f\"Indicized shape: {indicized.shape}\")\n",
    "            \n",
    "            # Create output dataset\n",
    "            output_shape = indicized.shape\n",
    "            dset_out = f_out.create_dataset(\n",
    "                dataset_name,\n",
    "                output_shape,\n",
    "                dtype=np.uint8\n",
    "            )\n",
    "            \n",
    "            # Write transformed data\n",
    "            dset_out[:] = indicized\n",
    "            \n",
    "            # Verify unique values\n",
    "            unique_values = np.unique(dset_out[:])\n",
    "            print(f\"  Dataset {dataset_name} unique values: {unique_values}\")\n",
    "            \n",
    "        print(\"Transformation complete!\")\n",
    "\n",
    "# Example usage:\n",
    "# transform_annotations(annotationDataFile, annotationIndicizedDataFile)\n",
    "\n",
    "# For debugging, let's also print the shape of the first dataset\n",
    "with h5py.File(annotationDataFile, 'r') as f:\n",
    "    first_dataset_name = list(f.keys())[0]\n",
    "    first_dataset = f[first_dataset_name][:]\n",
    "    print(f\"First dataset shape: {first_dataset.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example paths (adjust as needed)\n",
    "# annotationDataFile = \"/path/to/5channel/annotations.h5\"\n",
    "# annotationIndicizedDataFile = \"/path/to/output/indicized_annotations.h5\"\n",
    "\n",
    "indicize_annotations(annotationDataFile, annotationIndicizedDataFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hdf5_keys(hdf5_file: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Get list of dataset keys in an HDF5 file.\n",
    "\n",
    "    Args:\n",
    "        hdf5_file: Path to the HDF5 file\n",
    "\n",
    "    Returns:\n",
    "        list[str]: List of dataset keys in the file\n",
    "    \"\"\"\n",
    "    with h5py.File(hdf5_file, 'r') as f:\n",
    "        keys = list(f.keys())\n",
    "        print(f\"Keys in {hdf5_file}:\")\n",
    "        for key in keys:\n",
    "            print(f\"  {key}\")\n",
    "        return keys\n",
    "\n",
    "# Get keys from annotationIndicizedDataFile\n",
    "keys = get_hdf5_keys(annotationIndicizedDataFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def get_dataset_data(hdf5_file: str, key: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Get data from a specific dataset in an HDF5 file.\n",
    "\n",
    "    Args:\n",
    "        hdf5_file: Path to the HDF5 file\n",
    "        key: Key of the dataset to retrieve\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Data from the specified dataset\n",
    "    \"\"\"\n",
    "    with h5py.File(hdf5_file, 'r') as f:\n",
    "        data = f[key][:]\n",
    "        print(f\"Shape of dataset {key}: {data.shape}\")\n",
    "        return data\n",
    "\n",
    "# Get data for \"Napari_9_rev\" dataset\n",
    "key = random.choice(keys)\n",
    "example_data = get_dataset_data(annotationIndicizedDataFile, \"Narapi_34_rev\")\n",
    "print(key, example_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(example_data[30], cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.title('channels[4,30]')\n",
    "plt.axis('on')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabulate unique values and their counts in inmdi\n",
    "unique_values, counts = np.unique(example_data, return_counts=True)\n",
    "print(\"Value\\tCount\")\n",
    "print(\"-----\\t-----\")\n",
    "for val, count in zip(unique_values, counts):\n",
    "    print(f\"{val}\\t{count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def export_annotations_to_nnunet(annotationIndicizedDataFile, nnUNetRawFolder, frameKeys):\n",
    "    \"\"\"\n",
    "    Modified to only process common keys and verify count matches angiography\n",
    "    \"\"\"\n",
    "    labels_dir = os.path.join(nnUNetRawFolder, 'labelsTr')\n",
    "    Path(labels_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with h5py.File(annotationIndicizedDataFile, 'r') as f:\n",
    "        blockCounter = 0\n",
    "        \n",
    "        # Only iterate through common keys\n",
    "        for dataset_name, center_idx in frameKeys:\n",
    "            print(f\"Processing annotation dataset: {dataset_name} center_idx={center_idx}\")\n",
    "            # Get the shape of the dataset to check bounds\n",
    "            dataset_shape = f[dataset_name].shape\n",
    "            if center_idx >= dataset_shape[0]:\n",
    "                raise IndexError(f\"Index {center_idx} out of range for dataset {dataset_name} (0-{dataset_shape[0]-1})\")\n",
    "            anno_data = f[dataset_name][center_idx]\n",
    "            \n",
    "            filename = f'Angios_{blockCounter:05d}.png'\n",
    "            filepath = os.path.join(labels_dir, filename)\n",
    "            cv2.imwrite(filepath, anno_data)\n",
    "                \n",
    "            blockCounter += 1\n",
    "        \n",
    "        print(f\"Exported {blockCounter} label files\")\n",
    "        \n",
    "        # Verify we have the same number of cases as angiography\n",
    "        assert blockCounter == len(frameKeys), \\\n",
    "            f\"Mismatch in number of cases: Angiography had {len(frameKeys)}, Annotations had {blockCounter}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print first 50 frame keys to inspect the data\n",
    "print(\"First 50 frame keys:\")\n",
    "for i, (dataset_name, center_idx) in enumerate(frameKeys[:50]):\n",
    "    print(f\"{i}: {dataset_name}, center_idx={center_idx}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_annotations_to_nnunet(annotationIndicizedDataFile, nnUNetRawFolder, frameKeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(frameKeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... existing code ...\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Get current timestamp in a human-readable format\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "datasetJson = {\n",
    "    \"_comment\": f\"Dataset contains 5-channel angiography data at 7.5Hz (every other frame) with 5-frame neighborhoods. Labels include background (0), C (1), and V (2). Data sourced from WebknossosAngiogramsRevisedUInt8List.h5 and WebknossosAnnotationsRevisedIndicized-3.h5. Generated on {timestamp}.\",\n",
    "    \"channel_names\": {\n",
    "        \"0\": \"0\",\n",
    "        \"1\": \"1\",\n",
    "        \"2\": \"2\",\n",
    "        \"3\": \"3\",\n",
    "        \"4\": \"4\"\n",
    "    },\n",
    "    \"labels\": {\n",
    "        \"background\": 0,\n",
    "        \"catheter\": 1,\n",
    "        \"vessel\": 2\n",
    "    },\n",
    "    \"numTraining\": len(frameKeys),\n",
    "    \"file_ending\": \".png\"\n",
    "}\n",
    "\n",
    "# Write the dataset.json file\n",
    "import json\n",
    "dataset_json_path = os.path.join(nnUNetRawFolder, 'dataset.json')\n",
    "with open(dataset_json_path, 'w') as f:\n",
    "    json.dump(datasetJson, f, indent=4)\n",
    "\n",
    "print(f\"Created dataset.json at {dataset_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "angioshear.venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
