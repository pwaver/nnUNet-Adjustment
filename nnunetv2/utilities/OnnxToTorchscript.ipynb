{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX to TorchScript Conversion\n",
    "\n",
    "This notebook converts ONNX models to TorchScript format and validates the conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import onnx\n",
    "import dill\n",
    "from onnx2torch import convert\n",
    "import os\n",
    "import matplotlib.pyplot as plt  # Add this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running on Mac OS\n",
    "is_mac = os.name == 'posix' and os.uname().sysname == 'Darwin'\n",
    "print('posix' if os.name == 'posix' else 'not posix')\n",
    "print('mac' if is_mac else 'not mac')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths\n",
    "is_mac = os.name == 'posix' and os.uname().sysname == 'Darwin'\n",
    "rootPath = \"~/Projects/AWI/NetExploration/\" if is_mac else '/mnt/SliskiDrive/AWI/AWIBuffer/' # '/Volumes/Crucial X8/AWIBuffer/'\n",
    "onnxPath = rootPath + \"UNETR-nnUNetPlans_2d-DC_and_CE_loss-w-1-15-15-opset18.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnxPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if ONNX file exists\n",
    "if not os.path.exists(os.path.expanduser(onnxPath)):\n",
    "    raise FileNotFoundError(f\"ONNX file not found at path: {onnxPath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnxPath=\"UNETR-nnUNetPlans_2d-DC_and_CE_loss-w-1-15-15-opset18.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ONNX model to PyTorch\n",
    "modelPerOnnx = convert(onnxPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up device\n",
    "gpuDevice = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using device: {gpuDevice}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "modelPerOnnx = modelPerOnnx.to(gpuDevice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model with Random Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random test tensor\n",
    "random_tensor = torch.randn(1, 5, 512, 512, device=gpuDevice, dtype=torch.float32)\n",
    "print(\"Input tensor shape:\", random_tensor.shape)\n",
    "\n",
    "# Test model\n",
    "modelPerOnnx.eval()\n",
    "with torch.inference_mode():\n",
    "    result = modelPerOnnx(random_tensor)\n",
    "\n",
    "print(\"Output tensor shape:\", result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model with HDF5 Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "system = platform.system()\n",
    "if \"Darwin\" in system:\n",
    "    if os.path.isdir(\"/Volumes/Crucial X8\"):\n",
    "        dataDir = \"/Volumes/Crucial X8/AWIBuffer\"\n",
    "    else:\n",
    "        dataDir = \"/Users/billb/Projects/AWI/NetExploration\"\n",
    "elif \"Linux\" in system:\n",
    "    dataDir = \"/mnt/SliskiDrive/AWI/AWIBuffer\"\n",
    "else:\n",
    "    dataDir = None  # or some default path\n",
    "\n",
    "angiogramH5Path = dataDir + \"/AngiogramsDistilledUInt8List.h5\"\n",
    "angiogramH5Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Open the HDF5 file and print all dataset keys\n",
    "with h5py.File(angiogramH5Path, 'r') as f:\n",
    "    # Get all keys at root level\n",
    "    keys = list(f.keys())\n",
    "    print(\"Dataset keys in HDF5 file:\")\n",
    "    for key in keys:\n",
    "        print(f\"- {key}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load first angiogram from HDF5 file\n",
    "import random\n",
    "with h5py.File(angiogramH5Path, 'r') as f:\n",
    "    # Get first key\n",
    "    hdfKey = random.choice(keys)\n",
    "    print(f\"Loading dataset: {hdfKey}\")\n",
    "    # Load data into tensor\n",
    "    agram = torch.from_numpy(f[hdfKey][:]).float()\n",
    "    print(f\"Loaded tensor shape: {agram.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the 30th frame of the angiogram\n",
    "plt.imshow(agram[30], cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize angiogram by subtracting mean and dividing by standard deviation\n",
    "xagram = (agram - agram.mean()) / agram.std()\n",
    "print(f\"Normalized tensor shape: {xagram.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input tensor with 5 consecutive frames centered around frame 30\n",
    "start_idx = 28  # 30-2 to get 2 frames before\n",
    "end_idx = 33    # 30+3 to get 2 frames after (exclusive)\n",
    "z = xagram[start_idx:end_idx].unsqueeze(0)  # Add batch dimension\n",
    "print(f\"Input tensor shape: {z.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model and input tensor to GPU device\n",
    "gpuDevice = 'mps'\n",
    "modelPerOnnx = modelPerOnnx.to(gpuDevice)\n",
    "z = z.to(gpuDevice)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=modelPerOnnx(z)\n",
    "y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply softmax along dimension 1 (second dimension) which has size 3\n",
    "y = torch.nn.functional.softmax(y, dim=1)\n",
    "print(f\"Output tensor shape after softmax: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the 3rd channel (index 2) of the output\n",
    "plt.imshow(y[0, 2].cpu().detach().numpy(), cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.title('Output Channel 3')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of valid frame groups (each group has 5 consecutive frames)\n",
    "num_frames = xagram.shape[0]\n",
    "num_groups = num_frames - 4  # Each group needs 5 frames\n",
    "\n",
    "# Create tensor to hold all valid frame groups\n",
    "z5 = torch.zeros((num_groups, 5, 512, 512))\n",
    "\n",
    "# Fill z5 with overlapping groups of 5 consecutive frames\n",
    "for i in range(num_groups):\n",
    "    z5[i] = xagram[i:i+5]\n",
    "\n",
    "print(f\"Shape of tensor containing all valid 5-frame groups: {z5.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed z5 into the model and get the output\n",
    "y5 = modelPerOnnx(z5.to('mps'))\n",
    "y5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply softmax along dimension 1 (second dimension) which has size 3\n",
    "ys5 = torch.nn.functional.softmax(y5, dim=1)\n",
    "print(f\"Output tensor shape after softmax: {ys5.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the 3rd channel (index 2) of batch member 35\n",
    "plt.imshow(ys5[35, 2].cpu().detach().numpy(), cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.title('Output Channel 3 - Batch 35')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Back to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export model back to ONNX\n",
    "onnxOutputPath = onnxPath.replace(\".onnx\", \"-torch-onnx.onnx\")\n",
    "\n",
    "# Move both model and input tensor to CPU for export\n",
    "# model_for_export = modelPerOnnx.to(gpuDevice)\n",
    "# input_for_export = z5.to(gpuDevice)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    torch.onnx.export(modelPerOnnx.to('cpu'),\n",
    "                     z.to('cpu'),\n",
    "                     onnxOutputPath, \n",
    "                     export_params=True,\n",
    "                     opset_version=18, \n",
    "                     do_constant_folding=True,\n",
    "                     verbose=True,\n",
    "                     input_names=['input'],\n",
    "                     output_names=['output'], \n",
    "                     dynamic_axes={'input': {0: 'batch_size'}, \n",
    "                                 'output': {0: 'batch_size'}}, \n",
    "                     training=torch.onnx.TrainingMode.EVAL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Load PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save PyTorch model\n",
    "torchModelPath = onnxPath.replace(\".onnx\", \"-torch-onnx.pt\")\n",
    "torch.save(modelPerOnnx, torchModelPath)\n",
    "\n",
    "# Load and verify\n",
    "checkModel = torch.load(torchModelPath, weights_only=False)\n",
    "checkModel.eval()\n",
    "with torch.inference_mode():\n",
    "    result = checkModel(random_tensor)\n",
    "\n",
    "print(\"Verification output shape:\", result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TorchScript Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create example inputs with different batch sizes\n",
    "example_input_1 = torch.randn(2, 5, 512, 512).to(gpuDevice)\n",
    "example_input_2 = torch.randn(4, 5, 512, 512).to(gpuDevice)\n",
    "\n",
    "# Create traced model\n",
    "tracedModelperOnnx = torch.jit.trace(modelPerOnnx, example_input_1, check_trace=False)\n",
    "\n",
    "# Save traced model\n",
    "tracedModelPath = onnxPath.replace(\".onnx\", \"-torchscript-traced-onnx.pt\")\n",
    "tracedModelperOnnx.save(tracedModelPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Traced Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and test traced model\n",
    "tracedModel = torch.jit.load(tracedModelPath)\n",
    "tracedModel = tracedModel.to(gpuDevice)\n",
    "\n",
    "tracedModel.eval()\n",
    "with torch.inference_mode():\n",
    "    result = tracedModel(example_input_2)\n",
    "\n",
    "print(\"Traced model output shape:\", result.shape)\n",
    "\n",
    "# Test with different batch size\n",
    "result = tracedModelperOnnx(example_input_2)\n",
    "print(\"Different batch size output shape:\", result.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnunetv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
