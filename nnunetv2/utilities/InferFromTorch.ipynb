{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference from Torch of angiograms   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import onnx\n",
    "import dill as pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt  # Add this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running on Mac OS\n",
    "is_mac = os.name == 'posix' and os.uname().sysname == 'Darwin'\n",
    "print('posix' if os.name == 'posix' else 'not posix')\n",
    "print('mac' if is_mac else 'not mac')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths\n",
    "is_mac = os.name == 'posix' and os.uname().sysname == 'Darwin'\n",
    "rootPath = \"~/Projects/AWI/NetExploration/\" if is_mac else '/mnt/SliskiDrive/AWI/AWIBuffer/' # '/Volumes/Crucial X8/AWIBuffer/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = \"/home/ubuntu/U-Mamba-Adjustment/data/nets/UXlstmBot-nnUNetPlans_2d-DC_and_CE_loss-w-1-20-20-dill.pth\"\n",
    "model_path = rootPath + \"UXlstmBot-nnUNetPlans_2d-DC_and_CE_loss-w-1-20-20-dill.pth\"\n",
    "model_path = \"/Users/billb/Projects/AWI/NetExploration/UXlstmBot-nnUNetPlans_2d-DC_and_CE_loss-w-1-20-20-dill.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up device\n",
    "gpuDevice = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using device: {gpuDevice}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/billb/github/nnUNet-Adjustment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nnunetv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install blosc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(model_path, pickle_module=pickle, map_location=gpuDevice)\n",
    "# model.to(gpuDevice)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model with HDF5 Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "system = platform.system()\n",
    "if \"Darwin\" in system:\n",
    "    if os.path.isdir(\"/Volumes/Crucial X8\"):\n",
    "        dataDir = \"/Volumes/Crucial X8/AWIBuffer\"\n",
    "    else:\n",
    "        dataDir = \"/Users/billb/Projects/AWI/NetExploration\"\n",
    "elif \"Linux\" in system:\n",
    "    dataDir = \"/mnt/SliskiDrive/AWI/AWIBuffer\"\n",
    "else:\n",
    "    dataDir = None  # or some default path\n",
    "\n",
    "# dataDir = \"/home/ubuntu/data\"\n",
    "angiogramH5Path = dataDir + \"/AngiogramsDistilledUInt8List.h5\"\n",
    "angiogramH5Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Open the HDF5 file and print all dataset keys\n",
    "with h5py.File(angiogramH5Path, 'r') as f:\n",
    "    # Get all keys at root level\n",
    "    keys = list(f.keys())\n",
    "    print(\"Dataset keys in HDF5 file:\")\n",
    "    for key in keys:\n",
    "        print(f\"- {key}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load first angiogram from HDF5 file\n",
    "import random\n",
    "with h5py.File(angiogramH5Path, 'r') as f:\n",
    "    # Get first key\n",
    "    hdfKey = random.choice(keys)\n",
    "    print(f\"Loading dataset: {hdfKey}\")\n",
    "    # Load data into tensor\n",
    "    agram = torch.from_numpy(f[hdfKey][:]).float()\n",
    "    print(f\"Loaded tensor shape: {agram.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the 30th frame of the angiogram\n",
    "plt.imshow(agram[30], cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize angiogram by subtracting mean and dividing by standard deviation\n",
    "xagram = (agram - agram.mean()) / agram.std()\n",
    "print(f\"Normalized tensor shape: {xagram.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input tensor with 5 consecutive frames centered around frame 30\n",
    "start_idx = 28  # 30-2 to get 2 frames before\n",
    "end_idx = 33    # 30+3 to get 2 frames after (exclusive)\n",
    "z = xagram[start_idx:end_idx].unsqueeze(0)  # Add batch dimension\n",
    "print(f\"Input tensor shape: {z.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model and input tensor to GPU device\n",
    "# gpuDevice = 'mps'\n",
    "model = model.to(gpuDevice)\n",
    "z = z.to(gpuDevice)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    y = model(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply softmax along dimension 1 (second dimension) which has size 3\n",
    "y = torch.nn.functional.softmax(y, dim=1)\n",
    "print(f\"Output tensor shape after softmax: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the 3rd channel (index 2) of the output\n",
    "plt.imshow(y[0, 2].cpu().detach().numpy(), cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.title('Output Channel 3')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of valid frame groups (each group has 5 consecutive frames)\n",
    "num_frames = xagram.shape[0]\n",
    "num_groups = num_frames - 4  # Each group needs 5 frames\n",
    "\n",
    "# Create tensor to hold all valid frame groups\n",
    "z5 = torch.zeros((num_groups, 5, 512, 512))\n",
    "\n",
    "# Fill z5 with overlapping groups of 5 consecutive frames\n",
    "for i in range(num_groups):\n",
    "    z5[i] = xagram[i:i+5]\n",
    "\n",
    "print(f\"Shape of tensor containing all valid 5-frame groups: {z5.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the middle 10 frames from z5\n",
    "middle_idx = z5.shape[0] // 2  # Find middle index\n",
    "start_idx = middle_idx - 5    # 10 frames before middle\n",
    "end_idx = middle_idx + 5      # 10 frames after middle\n",
    "z5 = z5[start_idx:end_idx]     # Keep only middle 20 frames\n",
    "\n",
    "print(f\"Shape of tensor after selecting middle 20 frames: {z5.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed z5 into the model and get the output\n",
    "model = model.to(gpuDevice)\n",
    "z5 = z5.to(gpuDevice)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    y5 = model(z5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply softmax along dimension 1 (second dimension) which has size 3\n",
    "ys5 = torch.nn.functional.softmax(y5, dim=1)\n",
    "print(f\"Output tensor shape after softmax: {ys5.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the 3rd channel (index 2) of batch member 35\n",
    "plt.imshow(ys5[5, 2].cpu().detach().numpy(), cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.title('Output Channel 3 - Batch 35')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Back to ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export model back to ONNX\n",
    "onnxOutputPath = model_path.replace(\".pth\", \".onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export model back to ONNX\n",
    "onnxOutputPath = model_path.replace(\".pth\", \".onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Move both model and input tensor to CPU for export\n",
    "# model_for_export = modelPerOnnx.to(gpuDevice)\n",
    "# input_for_export = z5.to(gpuDevice)\n",
    "\n",
    "# with torch.inference_mode():\n",
    "#     torch.onnx.export(model,\n",
    "#                      z,\n",
    "#                      onnxOutputPath, \n",
    "#                      export_params=True,\n",
    "#                      #opset_version=18, \n",
    "#                      do_constant_folding=True,\n",
    "#                      verbose=True,\n",
    "#                      input_names=['input'],\n",
    "#                      output_names=['output'], \n",
    "#                      dynamic_axes={'input': {0: 'batch_size'}, \n",
    "#                                  'output': {0: 'batch_size'}}, \n",
    "#                      training=torch.onnx.TrainingMode.EVAL)\n",
    "torch.onnx.export(model,\n",
    "                     z,\n",
    "                     onnxOutputPath, \n",
    "                     export_params=True,\n",
    "                     #opset_version=18, \n",
    "                     do_constant_folding=True,\n",
    "                     verbose=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onnx_program = torch.onnx.export(model, z, dynamo=True)\n",
    "onnx_program = torch.onnx.dynamo_export(model, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.inference_mode():\n",
    "#     onnx_program = torch.onnx.dynamo_export(model,\n",
    "#                      z, \n",
    "#                      export_params=True,\n",
    "#                      #opset_version=18, \n",
    "#                      do_constant_folding=True,\n",
    "#                      verbose=True,\n",
    "#                      input_names=['input'],\n",
    "#                      output_names=['output'], \n",
    "#                      dynamic_axes={'input': {0: 'batch_size'}, \n",
    "#                                  'output': {0: 'batch_size'}}, \n",
    "#                      training=torch.onnx.TrainingMode.EVAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_program.save(onnxOutputPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Load PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save PyTorch model\n",
    "torchModelPath = onnxPath.replace(\".onnx\", \"-torch-onnx.pt\")\n",
    "torch.save(modelPerOnnx, torchModelPath)\n",
    "\n",
    "# Load and verify\n",
    "checkModel = torch.load(torchModelPath, weights_only=False)\n",
    "checkModel.eval()\n",
    "with torch.inference_mode():\n",
    "    result = checkModel(random_tensor)\n",
    "\n",
    "print(\"Verification output shape:\", result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TorchScript Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create example inputs with different batch sizes\n",
    "example_input_1 = torch.randn(2, 5, 512, 512).to(gpuDevice)\n",
    "example_input_2 = torch.randn(4, 5, 512, 512).to(gpuDevice)\n",
    "\n",
    "# Create traced model\n",
    "tracedModel = torch.jit.trace(model, example_input_1, check_trace=False)\n",
    "\n",
    "# Save traced model\n",
    "# tracedModelPath = model_path.replace(\".pth\", \"-torchscript-traced-onnx.pt\")\n",
    "# tracedModelperOnnx.save(tracedModelPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Traced Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and test traced model\n",
    "# tracedModel = torch.jit.load(tracedModelPath)\n",
    "tracedModel = tracedModel.to(gpuDevice)\n",
    "\n",
    "tracedModel.eval()\n",
    "with torch.inference_mode():\n",
    "    result = tracedModel(z5)\n",
    "\n",
    "print(\"Traced model output shape:\", result.shape)\n",
    "\n",
    "# Test with different batch size\n",
    "# result = tracedModelperOnnx(example_input_2)\n",
    "# print(\"Different batch size output shape:\", result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export model back to ONNX\n",
    "onnxOutputPath = model_path.replace(\".pth\", \".onnx\")\n",
    "onnxOutputPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(tracedModel,\n",
    "                     z,\n",
    "                     onnxOutputPath, \n",
    "                     export_params=True,\n",
    "                     #opset_version=18, \n",
    "                     do_constant_folding=True,\n",
    "                     verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import torch\n",
    "\n",
    "def get_torch_cuda_versions() -> Tuple[str, str, bool]:\n",
    "    \"\"\"\n",
    "    Get PyTorch and CUDA versions along with CUDA availability status.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[str, str, bool]\n",
    "        A tuple containing:\n",
    "        - PyTorch version (str)\n",
    "        - CUDA version (str) if available, 'N/A' if not\n",
    "        - CUDA availability status (bool)\n",
    "    \"\"\"\n",
    "    torch_version = torch.__version__\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "    cuda_version = torch.version.cuda if cuda_available else \"N/A\"\n",
    "    \n",
    "    return torch_version, cuda_version, cuda_available\n",
    "\n",
    "def print_versions() -> None:\n",
    "    \"\"\"\n",
    "    Print PyTorch and CUDA version information to console.\n",
    "    \"\"\"\n",
    "    torch_version, cuda_version, cuda_available = get_torch_cuda_versions()\n",
    "    \n",
    "    print(f\"PyTorch Version: {torch_version}\")\n",
    "    print(f\"CUDA Available: {cuda_available}\")\n",
    "    print(f\"CUDA Version: {cuda_version}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnunetArm64",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
