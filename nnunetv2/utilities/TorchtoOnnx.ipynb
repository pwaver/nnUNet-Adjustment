{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch to ONNX Conversion\n",
    "\n",
    "This notebook converts Torch to ONNX models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import onnx\n",
    "import dill\n",
    "from onnx2torch import convert\n",
    "import os\n",
    "import matplotlib.pyplot as plt  # Add this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/billb/github/nnUNet-Adjustment')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nnunetv2.training.nnUNetTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running on Mac OS\n",
    "is_mac = os.name == 'posix' and os.uname().sysname == 'Darwin'\n",
    "print('posix' if os.name == 'posix' else 'not posix')\n",
    "print('mac' if is_mac else 'not mac')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths\n",
    "is_mac = os.name == 'posix' and os.uname().sysname == 'Darwin'\n",
    "rootPath = \"~/Projects/AWI/NetExploration/\" if is_mac else '/mnt/SliskiDrive/AWI/AWIBuffer/' # '/Volumes/Crucial X8/AWIBuffer/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up device\n",
    "gpuDevice = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using device: {gpuDevice}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model with Random Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import a dill PyTorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchModelPath = rootPath + \"PlainConvUNet-nnUNetPlans_2d-DC_and_CE_loss-w-1-20-20-dill.pth\"\n",
    "torchModelPath =  \"/Users/billb/Projects/AWI/NetExploration/UXlstmBot-nnUNetPlans_2d-reduced3-DC_and_CE_loss-w-1-20-40-dill.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchModelPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if exists file at path torchModelPath\n",
    "if not os.path.exists(torchModelPath):\n",
    "    raise FileNotFoundError(f\"Model file not found at path: {torchModelPath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = torch.load(torchModelPath,map_location=gpuDevice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "\n",
    "# Test the model with a random input\n",
    "random_tensor = torch.randn(1, 5, 512, 512, device=gpuDevice, dtype=torch.float32)\n",
    "print(\"Input tensor shape:\", random_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    output = model(random_tensor)\n",
    "\n",
    "print(\"Output tensor shape:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model with HDF5 Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "system = platform.system()\n",
    "if \"Darwin\" in system:\n",
    "    if os.path.isdir(\"/Volumes/Crucial X8\"):\n",
    "        dataDir = \"/Volumes/Crucial X8/AWIBuffer\"\n",
    "    else:\n",
    "        dataDir = \"/Users/billb/Projects/AWI/NetExploration\"\n",
    "elif \"Linux\" in system:\n",
    "    dataDir = \"/mnt/SliskiDrive/AWI/AWIBuffer\"\n",
    "else:\n",
    "    dataDir = None  # or some default path\n",
    "\n",
    "angiogramH5Path = dataDir + \"/AngiogramsDistilledUInt8List.h5\"\n",
    "angiogramH5Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Open the HDF5 file and print all dataset keys\n",
    "with h5py.File(angiogramH5Path, 'r') as f:\n",
    "    # Get all keys at root level\n",
    "    keys = list(f.keys())\n",
    "    print(\"Dataset keys in HDF5 file:\")\n",
    "    for key in keys:\n",
    "        print(f\"- {key}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load first angiogram from HDF5 file\n",
    "import random\n",
    "with h5py.File(angiogramH5Path, 'r') as f:\n",
    "    # Get first key\n",
    "    hdfKey = random.choice(keys)\n",
    "    print(f\"Loading dataset: {hdfKey}\")\n",
    "    # Load data into tensor\n",
    "    agram = torch.from_numpy(f[hdfKey][:]).float()\n",
    "    print(f\"Loaded tensor shape: {agram.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the 30th frame of the angiogram\n",
    "plt.imshow(agram[30], cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize angiogram by subtracting mean and dividing by standard deviation\n",
    "xagram = (agram - agram.mean()) / agram.std()\n",
    "print(f\"Normalized tensor shape: {xagram.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input tensor with 5 consecutive frames centered around frame 30\n",
    "start_idx = 28  # 30-2 to get 2 frames before\n",
    "end_idx = 33    # 30+3 to get 2 frames after (exclusive)\n",
    "z = xagram[start_idx:end_idx].unsqueeze(0)  # Add batch dimension\n",
    "print(f\"Input tensor shape: {z.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = z.to(gpuDevice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=model(z)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply softmax along dimension 1 (second dimension) which has size 3\n",
    "y = torch.nn.functional.softmax(y, dim=1)\n",
    "print(f\"Output tensor shape after softmax: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the 3rd channel (index 2) of the output\n",
    "plt.imshow(y[0, 2].cpu().detach().numpy(), cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.title('Output Channel 3')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of valid frame groups (each group has 5 consecutive frames)\n",
    "num_frames = xagram.shape[0]\n",
    "num_groups = num_frames - 4  # Each group needs 5 frames\n",
    "\n",
    "# Create tensor to hold all valid frame groups\n",
    "z5 = torch.zeros((num_groups, 5, 512, 512))\n",
    "\n",
    "# Fill z5 with overlapping groups of 5 consecutive frames\n",
    "for i in range(num_groups):\n",
    "    z5[i] = xagram[i:i+5]\n",
    "\n",
    "print(f\"Shape of tensor containing all valid 5-frame groups: {z5.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed z5 into the model and get the output\n",
    "y5 = model(z5.to(gpuDevice))\n",
    "y5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply softmax along dimension 1 (second dimension) which has size 3\n",
    "ys5 = torch.nn.functional.softmax(y5, dim=1)\n",
    "print(f\"Output tensor shape after softmax: {ys5.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the 3rd channel (index 2) of batch member 35\n",
    "plt.imshow(ys5[35, 2].cpu().detach().numpy(), cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.title('Output Channel 3 - Batch 35')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export model back to ONNX\n",
    "onnxOutputPath = torchModelPath.replace(\".pth\", \".onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnxOutputPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Move both model and input tensor to CPU for export\n",
    "# model_for_export = modelPerOnnx.to(gpuDevice)\n",
    "# input_for_export = z5.to(gpuDevice)\n",
    "\n",
    "# with torch.inference_mode():\n",
    "#     torch.onnx.export(modelPerOnnx,\n",
    "#                      random_tensor,\n",
    "#                      onnxOutputPath, \n",
    "#                      export_params=True,\n",
    "#                      opset_version=18, \n",
    "#                      do_constant_folding=True,\n",
    "#                      verbose=True,\n",
    "#                      input_names=['input'],\n",
    "#                      output_names=['output'], \n",
    "#                      dynamic_axes={'input': {0: 'batch_size'}, \n",
    "#                                  'output': {0: 'batch_size'}}, \n",
    "#                      training=torch.onnx.TrainingMode.EVAL)\n",
    "\n",
    "# with torch.inference_mode():\n",
    "#     torch.onnx.export(\n",
    "#     model,\n",
    "#     random_tensor,\n",
    "#     onnxOutputPath,\n",
    "#     export_params=True,\n",
    "#     opset_version=14,\n",
    "#     do_constant_folding=True,\n",
    "#     input_names=['input'],\n",
    "#     output_names=['output'],\n",
    "#     dynamic_axes={\n",
    "#         'input': {0: 'batch_size'},  # First dimension is batch size\n",
    "#         'output': {0: 'batch_size'}\n",
    "#     }\n",
    "# )\n",
    "\n",
    "with torch.inference_mode():\n",
    "    torch.onnx.export(\n",
    "    model,\n",
    "    z,\n",
    "    onnxOutputPath,\n",
    "    export_params=True,\n",
    "    opset_version=18,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={\n",
    "        'input': {0: 'batch_size'},\n",
    "        'output': {0: 'batch_size'}\n",
    "    },\n",
    "    keep_initializers_as_inputs=True,  # This can help with some batch dimension issues\n",
    "    do_constant_folding=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnunetv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
